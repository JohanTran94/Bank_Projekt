{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import great_expectations as gx\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"`result_format` configured at the Validator-level*\")\n",
    "\n",
    "\n",
    "# --- Utility to identify the transaction file ---\n",
    "def identify_transaction_csv(data_dir: Path) -> Path:\n",
    "    for file in data_dir.glob(\"*.csv\"):\n",
    "        try:\n",
    "            df = pd.read_csv(file, nrows=1)\n",
    "            columns = set(df.columns.str.lower())\n",
    "            if {\"transaction_id\", \"amount\", \"sender_account\"}.issubset(columns):\n",
    "                return file\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file}: {e}\")\n",
    "    raise FileNotFoundError(\"No transaction CSV file found in data/\")\n",
    "\n",
    "\n",
    "# --- Load transaction CSV ---\n",
    "DATA_DIR = Path().resolve() / \"data\"\n",
    "transaction_csv = identify_transaction_csv(DATA_DIR)\n",
    "df_trans = pd.read_csv(transaction_csv)\n",
    "print(f\"Loaded transaction file: {transaction_csv.name} with {len(df_trans)} rows\")\n",
    "\n",
    "# --- Set up Great Expectations context ---\n",
    "context = gx.get_context()\n",
    "datasource = context.data_sources.add_pandas(name=\"pandas_source\")\n",
    "data_asset = datasource.add_dataframe_asset(name=\"transactions_data\")\n",
    "batch_def = data_asset.add_batch_definition_whole_dataframe(name=\"batch_def\")\n",
    "batch = batch_def.get_batch(batch_parameters={\"dataframe\": df_trans})\n",
    "\n",
    "# --- Create expectation suite and validator ---\n",
    "suite = gx.core.ExpectationSuite(name=\"transactions_suite\")\n",
    "validator = context.get_validator(batch=batch, expectation_suite=suite)\n",
    "\n",
    "# --- Add validation rules ---\n",
    "validator.expect_column_values_to_not_be_null(\"transaction_id\")\n",
    "validator.expect_column_values_to_be_unique(\"transaction_id\")\n",
    "\n",
    "validator.expect_column_values_to_match_strftime_format(\"timestamp\", \"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "validator.expect_column_values_to_be_between(\"amount\", min_value=0.01, max_value=100000)\n",
    "\n",
    "validator.expect_column_values_to_be_in_set(\n",
    "    \"currency\",\n",
    "    [\"SEK\", \"USD\", \"EUR\", \"DKK\", \"JPY\", \"ZMW\", \"NOK\", \"ZAR\", \"RMB\", \"GBP\"]\n",
    ")\n",
    "\n",
    "validator.expect_column_values_to_be_in_set(\"transaction_type\", [\"incoming\", \"outgoing\"])\n",
    "\n",
    "validator.expect_column_values_to_match_regex(\n",
    "    \"receiver_account\", r\"^(?:SE\\d{4}[A-Z]{4}\\d{14}|GB\\d{2}[A-Z]{4}\\d{14})$\"\n",
    ")\n",
    "validator.expect_column_values_to_match_regex(\n",
    "    \"sender_account\", r\"^(?:SE\\d{4}[A-Z]{4}\\d{14}|GB\\d{2}[A-Z]{4}\\d{14})$\"\n",
    ")\n",
    "\n",
    "validator.expect_column_values_to_not_be_null(\"sender_country\")\n",
    "validator.expect_column_values_to_not_be_null(\"receiver_country\")\n",
    "validator.expect_column_values_to_not_be_null(\"sender_municipality\")\n",
    "validator.expect_column_values_to_not_be_null(\"receiver_municipality\")\n",
    "\n",
    "# --- Print rows with missing receiver_country ---\n",
    "missing_country = df_trans[df_trans[\"receiver_country\"].isnull()]\n",
    "if not missing_country.empty:\n",
    "    print(\"Rows with missing receiver_country:\")\n",
    "    print(missing_country.head())\n",
    "\n",
    "# --- Print rows with missing receiver_municipality ---\n",
    "missing_municipality = df_trans[df_trans[\"receiver_municipality\"].isnull()]\n",
    "if not missing_municipality.empty:\n",
    "    print(\"Rows with missing receiver_municipality:\")\n",
    "    print(missing_municipality.head())\n",
    "\n",
    "# --- Fill null values with placeholder for output copy ---\n",
    "df_trans_copy = df_trans.copy()\n",
    "df_trans_copy[\"receiver_country\"].fillna(\"Unknown\", inplace=True)\n",
    "df_trans_copy[\"receiver_municipality\"].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "# --- Flag transactions by criteria ---\n",
    "df_trans[\"flagged\"] = (\n",
    "        (df_trans[\"amount\"] > 100000) |\n",
    "        (df_trans[\"notes\"].str.lower().str.contains(\"gift|cash|transfer\", na=False))\n",
    ")\n",
    "\n",
    "flagged_transactions = df_trans[df_trans[\"flagged\"]]\n",
    "print(\"Flagged transactions:\")\n",
    "print(flagged_transactions)\n",
    "\n",
    "# --- Save cleaned copy to CSV ---\n",
    "report_dir = Path(\"report\")\n",
    "report_dir.mkdir(exist_ok=True)\n",
    "df_trans_copy.to_csv(report_dir / \"transactions_cleaned.csv\", index=False)\n",
    "\n",
    "# --- Run validation and export results ---\n",
    "results = validator.validate(result_format={\"result_format\": \"COMPLETE\"})\n",
    "\n",
    "print(\"Validation results:\")\n",
    "print(results)\n",
    "\n",
    "# --- Save validation results as JSON ---\n",
    "output_path = report_dir / \"validation_results_transactions.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(results.to_json_dict(), f, indent=4)\n"
   ],
   "id": "a6507a6a7896d1a9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
